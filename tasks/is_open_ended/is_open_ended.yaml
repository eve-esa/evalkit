task: is_open_ended
dataset_path: 'eve-esa/eve-is-open-ended'
test_split: 'train'
doc_to_text: "Q: {{question}}\n"
doc_to_target: '{{answer}}'
gen_prefix: 'A: '
description: "Answer these questions:\n"
process_results: !function utils.process_results
metric_list:
  - metric: 'bertscore_f1'
    aggregation: mean
  - metric: 'bertscore_precision'
    aggregation: mean
  - metric: 'bertscore_recall'
    aggregation: mean
  - metric: 'bertscore_accuracy'
    aggregation: mean
  - metric: 'llm_judge_accuracy'
    aggregation: mean
#  - metric: 'llm_judge_accuracy_2'
#    aggregation: mean
#  - metric: 'bleu_score'
#    aggregation: mean
#  - metric: 'bleurt_score'
#    aggregation: mean
#  - metric: 'bleu_accuracy'
#    aggregation: mean
#  - metric: 'bleurt_accuracy'
#    aggregation: mean
metadata:
  version: 2.0
dataset_kwargs:
  trust_remote_code: true
num_fewshot: 2
fewshot_split: 'train'
fewshot_config:
  sampler: first_n
