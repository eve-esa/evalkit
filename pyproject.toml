[project]
name = "eve-evaluation"
version = "0.1.0"
description = "EVE (Earth and environmental sciences Vocabulary Evaluation) - LLM evaluation framework"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "evaluate>=0.4.0",
    "numpy>=1.26.4",
    "lm-eval @ https://github.com/eve-esa/lm-evaluation-harness.git",
    "datasets>=2.0.0",
    "torch>=2.0.0",
    "pandas>=2.0.0",
    "tqdm>=4.65.0",
    "bert-score>=0.3.13",
    "click>=8.1.0",
    "openai>=1.0.0",
    "transformers>=4.30.0",
    "langchain-core>=0.1.0",
    "langchain-community>=0.0.1",
    "pydantic>=2.0.0",
    "litellm>=1.0.0",
    "pyyaml>=6.0.0",
    "wandb==0.23.0",
    "sentencepiece>=0.2.1",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
    "pre-commit>=3.0.0",
    "mkdocs-material>=9.7.0",
    "mkdocstrings[python]>=1.0.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.metadata]
allow-direct-references = true


[tool.hatch.build.targets.wheel]
packages = ["metrics", "tasks"]

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I"]
ignore = ["E501"]

[tool.black]
line-length = 100
target-version = ["py310"]
