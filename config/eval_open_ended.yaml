# Tasks:
#   - open_ended_default: 0-shot and 5-shot
#   - open_ended_w_context_default: 0-shot and 5-shot

constants:
    hf_token: EMPTY
    tasks:
    # Open-ended - 0-shot
    - name: open_ended_default_0shot
      task_name: open_ended_default
      num_fewshot: 0
      max_tokens: 2048
      model_type: local-chat-completions
      apply_chat_template: true

    # Open-ended - 5-shot
    - name: open_ended_default_5shot
      task_name: open_ended_default
      num_fewshot: 5
      max_tokens: 2048
      model_type: local-chat-completions
      apply_chat_template: true

    # Open-ended with context - 0-shot
    - name: open_ended_w_context_default_0shot
      task_name: open_ended_w_context_default
      num_fewshot: 0
      max_tokens: 2048
      model_type: local-chat-completions
      apply_chat_template: true

    # Open-ended with context - 5-shot
    - name: open_ended_w_context_default_5shot
      task_name: open_ended_w_context_default
      num_fewshot: 5
      max_tokens: 2048
      model_type: local-chat-completions
      apply_chat_template: true

models:
  - name: NAME
    base_url: URL
    api_key: EMPTY
    temperature: 0.0
    num_concurrent: 32
    timeout: 600
    tokenizer: mistralai/Mistral-Small-3.1-24B-Instruct-2503
    tasks: !ref tasks

output_dir: evals_outputs
